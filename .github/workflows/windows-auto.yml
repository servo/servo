# Auto runner build for: windows.yml
# Runs the underlying workflow on a self-hosted runner if available.

# To create an auto runner build for another workflow:
# 1. Add a “unique-id” boolean input to the underlying workflow, then insert
#    “[unique-id]” into the name of any of its jobs when the input is present.
# 2. Add a “self-hosted-runner” boolean input to the underlying workflow, then
#    set jobs.*.runs-on to ${{ inputs.self-hosted-runner && '...' || '...' }}
#    as needed in the underlying workflow.
# 3. Copy this file and name it something like “foo-auto.yml”.
# 4. Follow the instructions in the lines marked “EDIT” below.

# EDIT: Choose a name that reflects that of the underlying workflow.
name: Windows (auto runner)

# EDIT: Keep this block in sync with the underlying workflow, to ensure all of
# its inputs are forwarded correctly. There is no way to make this generic for
# workflows with other inputs, unless we generate the YAML programmatically!
on:
  workflow_call:
    inputs:
      profile:
        required: false
        default: "release"
        type: string
      unit-tests:
        required: false
        default: false
        type: boolean
      upload:
        required: false
        default: false
        type: boolean
      github-release-id:
        required: false
        type: string
  workflow_dispatch:
    inputs:
      profile:
        required: false
        default: "release"
        options: ["release", "debug", "production"]
        type: choice
      unit-tests:
        required: false
        default: false
        type: boolean
      upload:
        required: false
        default: false
        type: boolean

jobs:
  auto:
    name: Run on best runner
    runs-on: ubuntu-latest
    steps:
      - id: dispatch
        name: Dispatch workflow
        # EDIT: Set workflow_filename to point to the underlying workflow.
        # EDIT: Keep dispatch_workflow() in sync with the underlying workflow,
        # to ensure all of its inputs are forwarded correctly. There is no way
        # to make this generic for workflows with other inputs, unless we
        # generate the YAML programmatically!
        run: |
          workflow_filename=windows.yml

          dispatch_workflow() {
            gh api --method POST "$workflow_endpoint/dispatches" \
              -f 'inputs[profile]=${{ inputs.profile }}' \
              -f 'inputs[unit-tests]=${{ inputs.unit-tests }}' \
              -f 'inputs[upload]=${{ inputs.upload }}' \
              -f 'inputs[github-release-id]=${{ inputs.github-release-id }}' \
              -f 'ref=${{ github.ref }}' \
              "$@"
          }

          export GH_TOKEN=${{ secrets.GITHUB_TOKEN }}
          workflow_endpoint=/repos/${{ github.repository }}/actions/workflows/$workflow_filename

          # Generate unique ids that help us reliably find our dispatched
          # workflow runs, while distinguishing them from other auto-runner
          # builds started by the original workflow. This will end up in the
          # friendly name of a job in the underlying workflow, since we can’t
          # use expressions in the name of the underlying workflow as a whole.
          random32=$(LC_ALL=C < /dev/urandom tr -dC 0-9a-f 2> /dev/null | head -c 8)
          unique_id_base=${{ github.repository }}/${{ github.run_id }}/$random32
          self_hosted_id=$unique_id_base/self-hosted
          github_hosted_id=$unique_id_base/github-hosted

          # Wait for a workflow run to appear with the expected unique id,
          # setting the $workflow_run_url global to the workflow run url.
          # There is no way to identify the dispatched workflow without looking
          # up all workflow runs, and for each run, looking up its jobs!
          wait_for_workflow_run_to_appear() {
            local unique_id=$1
            local tries=10

            # Contrary to the API docs, ?created must have offset +00:00 (UTC),
            # or no results will be returned.
            local created_after=$(date -u -Iseconds -d @$(($(date +\%s) - 60)))
            local created='?created=>'"$created_after"

            local result=
            local i=0
            while [ $i -lt $tries ]; do
              echo "Waiting for workflow run to appear... ($((tries - i)) tries left)"

              # Store the response in a file and loop through indices, because
              # bash runs piped-into-while-read loops in a subshell, making it
              # hard to set variables. zsh does not have this problem, but
              # GitHub’s image only comes with bash.
              local runs=$(mktemp)
              gh api "$workflow_endpoint/runs?$created" > $runs

              local j=0
              while [ $j -lt "$(jq '.workflow_runs | length' $runs)" ]; do
                local jobs_url=$(jq -er '.workflow_runs['$j'].jobs_url' $runs)
                result=$(
                  gh api "$jobs_url" \
                    | jq -r --arg id "$unique_id" \
                      '.jobs[] | select(.name | contains("[" + $id + "]")) | .run_url'
                )
                if [ -n "$result" ]; then
                  workflow_run_url=$result
                  return 0
                fi
                j=$((j + 1))
              done
              sleep 1
              i=$((i + 1))
            done
            echo "No workflow run found!"
            exit 1
          }

          echo "Dispatching workflow on self-hosted runner"
          dispatch_workflow -f 'inputs[unique-id]='"$self_hosted_id" -f 'inputs[self-hosted-runner]=true'
          wait_for_workflow_run_to_appear "$self_hosted_id"
          self_hosted_run_url=$workflow_run_url
          echo "Self-hosted workflow run: $self_hosted_run_url"

          tries=10
          i=0
          while [ $i -lt $tries ]; do
            self_hosted_run_status=$(gh api "$self_hosted_run_url" -q .status)
            echo "Workflow run status: $self_hosted_run_status ($((tries - i)) tries left)"
            if [ "$self_hosted_run_status" != queued ]; then
              break
            fi
            sleep 1
            i=$((i + 1))
          done
          if [ "$self_hosted_run_status" != queued ]; then
            echo "url=$self_hosted_run_url" >> $GITHUB_OUTPUT
            exit
          fi

          echo 'Self-hosted workflow run still queued! Cancelling run'
          gh api --method POST "$self_hosted_run_url/cancel" --silent

          echo "Dispatching workflow on GitHub-hosted runner"
          dispatch_workflow -f 'inputs[unique-id]='"$github_hosted_id" -f 'inputs[self-hosted-runner]=false'
          wait_for_workflow_run_to_appear "$github_hosted_id"
          github_hosted_run_url=$workflow_run_url
          echo "GitHub-hosted workflow run: $github_hosted_run_url"
          echo "url=$github_hosted_run_url" >> $GITHUB_OUTPUT

      - name: Click here for build results
        run: |
          export GH_TOKEN=${{ secrets.GITHUB_TOKEN }}
          gh api '${{ steps.dispatch.outputs.url }}' -q .html_url

      - name: Wait for workflow run to finish
        run: |
          export GH_TOKEN=${{ secrets.GITHUB_TOKEN }}

          i=0
          while true; do
            run_conclusion=$(gh api '${{ steps.dispatch.outputs.url }}' -q .conclusion)
            if [ -n "$run_conclusion" ]; then
              echo "Workflow run conclusion: $run_conclusion"
              if [ "$run_conclusion" = success ]; then
                exit 0
              else
                exit 1
              fi
            else
              if [ $((i % 10)) -eq 0 ]; then
                echo "Waiting for workflow run to finish... ($i)"
              fi
            fi
            sleep 1
            i=$((i + 1))
          done

      - name: Copy artifacts from workflow run
        run: |
          export GH_TOKEN=${{ secrets.GITHUB_TOKEN }}

          # Store the response in a file and loop through indices, because
          # bash runs piped-into-while-read loops in a subshell, making it
          # hard to set variables. zsh does not have this problem, but
          # GitHub’s image only comes with bash.
          artifacts=$(mktemp)
          gh api '${{ steps.dispatch.outputs.url }}/artifacts' > $artifacts

          # There is no way to download artifacts from other workflow runs in
          # actions/download-artifact, so we need to roll our own!
          i=0
          while [ $i -lt "$(jq '.artifacts | length' $artifacts)" ]; do
            echo "Downloading artifact: $(jq -er '.artifacts['$i'].name' $artifacts)"
            artifact_zip=$(mktemp)
            gh api "$(jq -er '.artifacts['$i'].archive_download_url' $artifacts)" > $artifact_zip
            unzip $artifact_zip
            i=$((i + 1))
          done
          ls -l

      # EDIT: Add an upload step for each artifact in the underlying workflow.
      # The artifact files are automatically downloaded from the underlying
      # workflow run and extracted to the current directory.
      - uses: actions/upload-artifact@v4
        with:
          name: cargo-timings-windows
          path: cargo-timings-*
      - uses: actions/upload-artifact@v4
        with:
          name: win
          path: Servo.exe
