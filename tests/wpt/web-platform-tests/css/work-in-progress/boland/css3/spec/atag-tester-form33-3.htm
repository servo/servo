<html>
<head>

<title>ATAG2.0 Tester (Author) Template (Form) 33-3 - for Success Criterion 3.3-3</title>

<style type="text/css">


h2 {font-size: 150%;}
h1 {font-size: 200%;}


</style>
</head>

<body>

<h1>
ATAG 2.0 Tester (Author) Template (Form) 33-3 - for Success Criterion 3.3-3
</h1>
<p>
This form is divided into four parts: Part 1 - General Information, Part 2 - General Questions,
Part 3 - Specific Questions, and Part 4 - Supplemental Questions.  NOTE: The (link to) ATAG2.0
techniques may be included in Part 3 questions, but there may be other questions to answer in Part 3.
Therefore, the questions may need to be reorganized, so that for some questions, every question
may need to be answered, but for others, only one out of a set of questions (related to ATAG2.0
techniques) may need to be answered.  If you need any additional help (for example, steps to take
or resources to access) in order to answer any of the questions following, please email:
(mailto) public-atag-tests@w3.org.  It is desired that this form be easy and quick to fill out.
<hr>
<h2>Part 1 - General Information</h2>
<p>
DISCLAIMER: Data entered on this form is informative only.  The submitter bears all responsibility for the
accuracy of the data.  The data entered on this form 
may be reviewed by the W3C AUWG?
<p>
 Answers to all questions are
required (except for those questions marked OPTIONAL)(however, you may refer to answers on other templates if you wish); if you feel a question is not applicable, just write "not applicable" and
specify why.  If you need additional ATAG information (including access to the ATAG2.0 spec and techniques) to complete this form, you may go
to the ATAG site.  If you need additional WAI testing resources, go to ?  Please submit this form to "testreport site".  This information
will be made public.  This information will be made accessible.  After submitting this form, you may proceed directly to
the <a href="atag-tester-form35-2.htm">Tester Form for Success Criterion 3.5-2</a>, or back to the <a href="ATAG20testsuite.htm">
main ATAG test page</a>.  It is possible that some results may be machine-reportable, in
which case the developer should have noted this information on the developer's form (link?), and you
could attach the machine-reportable results to this form.  There are no dependencies on other tester forms
 for filling out this form.  Thank you.

<h3>TEST PURPOSE:</h3> To evaluate an authoring tool's formats according to SC3.3

<h3>TEST AGAINST:</h3> Success Criterion 3.3 - 
<ul>
<li>The authoring tool must always provide a repair (automated repair, semi-automated repair or
manual repair) for each applicable requirement to conform to WCAG Level AAA
<li>For accessibility problems for which an authoring tool provides only manual repairs, the repair
instructions must always be directly linked from the corresponding check.
</ul>  

<hr>
<h2>Part 2 - General Questions (may be replaced by Conformance Profile?)</h2> 
<h3>
Name of Tester (Author):
</h3>
<p>
<br>
<br>
<br>
<h3>
Date and Version of ATAG2.0 Specification Tested Against (if different than 22 Nov 04 WD):
</h3>
<p>
<br>
<br>
<br>
<h3>
Contact Info of Tester/Author(s):
</h3>
<p>
<br>
<br>
<br>
<h3>
Address of Tester/Author(s):
</h3>
<p>
<br>
<br>
<br>
<h3>
Email of Tester/Author(s):
</h3>
<p>
<br>
<br>
<br>
<h3>
Phone Number(s) of Tester/Author(s):
</h3>
<p>
<br>
<br>
<br>
<h3>
Fax# of Tester/Author(s):
</h3>
<p>
<br>
<br>
<br>
<h3>
Authoring Tool Tested (please be specific) - category of authoring tool,
format(s) output from authoring tool, and platform that authoring tool uses)
(indicate if authoring tool is a bundled tool):
</h3>
<p> 
<br>
<br>
<br>
<h3>
Have you accessed the developers form (if available) (link?) for this particular authoring tool and success criterion?  If so, do you have any questions on
any of that information?  It is not necessary (but desirable) for the developer to have submitted a form for the tool you
are testing.  
</h3>
<p>
<br>
<br>
<br>
<hr>





<h2>Part 3 - Specific Test Questions for Success Criterion 3.3</h2>
Note: These questions may in the future refer back in a one-to-one relationship with information on each question
provided by the tool developer on a separate template?  You have access to the developer's information
for each question.   For more information on ATAG2.0 spec go to ?.
<p>
INVESTIGATION:
<p>
<ul>
<li>How did the authoring tool provide automated checks to ensure meeting WCAG Level AA requirements? 
 (may require authoring actions) (NOTE: MAY WANT TO STOP AT THIS POINT TO GET INFORMATION NECESSARY TO ANSWER FOLLOWING QUESTIONS,
AND RETURN TO FORM AT THIS POINT!) 
 
<br>
<br>
<br>

<li>How did the authoring tool provide semi-automated checks to ensure meeting WCAG Level AA requirements? 
 (may require authoring actions) (NOTE: MAY WANT TO STOP AT THIS POINT TO GET INFORMATION NECESSARY TO ANSWER FOLLOWING QUESTIONS,
AND RETURN TO FORM AT THIS POINT!) 
 
<br>
<br>
<br>

<li>How did the authoring tool provide manual checks to ensure meeting WCAG Level AA requirements? 
 (may require authoring actions) (NOTE: MAY WANT TO STOP AT THIS POINT TO GET INFORMATION NECESSARY TO ANSWER FOLLOWING QUESTIONS,
AND RETURN TO FORM AT THIS POINT!) 
 
<br>
<br>
<br>
<li>How did the authoring tool inform you of failed check results (see previous?)?  (may require authoring actions) (NOTE: MAY WANT TO STOP AT THIS POINT TO GET INFORMATION NECESSARY TO ANSWER FOLLOWING QUESTIONS,
AND RETURN TO FORM AT THIS POINT!) 
 
<br>
<br>
<br>



</ul>
<p>
<!--
<h2> [(link to developer's) 7.2.1.1 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate the enabling of user
 input/output choice according to Part 7.2.1.1 of ISO16071:2002(E) (please be specific-if (so/not), how was it (so/not) demonstrated?)?
What test procedure did you use?  What test environment did you use?</h2>
<p>
<h2> [(link to developer's) 7.2.2 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate enabling the user to
 perform task effectively with any single input device according to Part 7.2.2 of ISO16071:2002(E)(please be specific
-if (so/not), how was it (so/not) demonstrated)?  What test procedure did you use?  What test environment did you use?</h2>
<p>
<h2> [(link to developer's) 7.2.4 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate enabling user setting
 of timed responses according to Part 7.2.4 of ISO16071:2002(E)(please be specific-if (so/not), how was it (so/not) demonstrated)?
What test procedure did you use?  What test environment did you use?</h2>
<p>
<h2> [(link to developer's) 7.2.10 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate an avoidance of
 seizure-inducing blink rates according to Part 7.2.10 of ISO16071:2002(E)(please be specific-if (so/not), how was it (so/not) demonstrated)?
What test procedure did you use?  What test environment did you use?</h2>
<p>
<h2> [(link to developer's) 7.2.12 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate enabling user control
 of time-sensitive presentation of information according to Part 7.2.12 of ISO16071:2002(E)(please be specific-if (so/not), how
 was it (so/not) demonstrated)?  What test procedure did you use?  What test environment did you use?</h2>

<p>
<h2> [(link to developer's) 7.3.1 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate the use of system-standard input/output
 according to Part 7.3.1 of ISO16071:2002(E)(please be specific-if (so/not), how
 was it (so/not) demonstrated)?  What test procedure did you use?  What test environment did you use?</h2>
<p>
<h2> [(link to developer's) 7.3.2 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate the provision of object labels
 according to Part 7.3.2 of ISO16071:2002(E)(please be specific-if (so/not), how
 was it (so/not) demonstrated)?  What test procedure did you use?  What test environment did you use?</h2>
<p>
<h2> [(link to developer's) 7.3.3 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate how to make event notification
available to assistive technologies
 according to Part 7.3.3 of ISO16071:2002(E)(please be specific-if (so/not), how
 was it (so/not) demonstrated)?  What test procedure did you use?  What test environment did you use?</h2>
<p>
<h2> [(link to developer's) 7.3.4 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate how to make object attributes available to
assistive technologies according to Part 7.3.4 of ISO16071:2002(E)(please be specific-if (so/not), how
 was it (so/not) demonstrated)?  What test procedure did you use?  What test environment did you use?</h2>
<p>
<h2> [(link to developer's) 7.3.5 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate the use of system-standard input/output
 according to Part 7.3.5 of ISO16071:2002(E)(please be specific-if (so/not), how
 was it (so/not) demonstrated)?  What test procedure did you use?  What test environment did you use?</h2>
<p>
<h2> [(link to developer's) 7.4.11 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate the reserving of accessibility key mappings
 according to Part 7.4.11 of ISO16071:2002(E)(please be specific-if (so/not), how
 was it (so/not) demonstrated)?  What test procedure did you use?  What test environment did you use?</h2>
<p>
<h2> [(link to developer's) 7.4.13 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate the separation of keyboard navigation and activation
 according to Part 7.4.13 of ISO16071:2002(E)(please be specific-if (so/not), how
 was it (so/not) demonstrated)?  What test procedure did you use?  What test environment did you use?</h2>
<p>
<h2> [(link to developer's) 7.5.2 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate the enabling of location of button functions
 according to Part 7.5.2 of ISO16071:2002(E)(please be specific-if (so/not), how
 was it (so/not) demonstrated)?  What test procedure did you use?  What test environment did you use?</h2>
<p>
<h2> [(link to developer's) 7.5.9 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate the provision of alternatives to chorded key presses
 according to Part 7.5.9 of ISO16071:2002(E)(please be specific-if (so/not), how
 was it (so/not) demonstrated)?  What test procedure did you use?  What test environment did you use?</h2>
<p>
<h2> [(link to developer's) 7.6.1 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate font customization and legibility according to Part 7.6.1 of ISO16071:2002(E)(please be specific
if (so/not), how was it (so/not) demonstrated)?
What test procedure did you use?  What test environment did you use?</h2>  
<p>
<h2> [(link to developer's) 7.8.1 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate alternatives to the use of color as the sole source of information according to Part 7.8.1 of 
ISO16071:2002(E)(please be specific - if (so/not), how was it (so/not) demonstrated)?
What test procedure did you use?  What test environment did you use?</h2>  
<p>
<h2> [(link to developer's) 7.8.6 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate provision of alternatives to coding by hue according to Part 7.8.6 of ISO16071:2002(E)(please be specific
if (so/not), how was it (so/not) demonstrated)?
What test procedure did you use?  What test environment did you use?</h2>  
<p>
<h2> [(link to developer's) 7.9.5 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate allowing users to choose visual indication of audio output according to Part 7.9.5 of ISO16071:2002(E)
(please be specific - if (so/not), how was it (so/not) demonstrated)?
What test procedure did you use?  What test environment did you use?</h2>  
<p>
<h2> [(link to developer's) 7.10.1 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate allowing task-relevant warning or error information to persist according to Part 7.10.1 of ISO16071:2002(E)
(please be specific - if (so/not), how was it (so/not) demonstrated)?
What test procedure did you use?  What test environment did you use?</h2>  
<p>
<h2> [(link to developer's) 7.12.3 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate enabling cursor and pointer customization according to Part 7.12.3 of ISO16071:2002(E)
(please be specific - if (so/not), how was it (so/not) demonstrated)?
What test procedure did you use?  What test environment did you use?</h2>  
<p>
<h2> [(link to developer's) 7.13.1 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate enabling non-pointer navigation directly to windwows according to Part 7.13.1 of ISO16071:2002(E)
(please be specific - if (so/not), how was it (so/not) demonstrated)?
What test procedure did you use?  What test environment did you use?</h2>  
<p>
<h2> [(link to developer's) 7.14.1 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate provision of focus cursor according to Part 7.14.1 of ISO16071:2002(E)
(please be specific - if (so/not), how was it (so/not) demonstrated)?
What test procedure did you use?  What test environment did you use?</h2>  
<p>
<h2> [(link to developer's) 7.14.2 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate provision of keyboard navigation according to Part 7.14.2 of ISO16071:2002(E)
(please be specific - if (so/not), how was it (so/not) demonstrated)?
What test procedure did you use?  What test environment did you use?</h2>  
<p>
<h2> [(link to developer's) 7.14.3 entry?] For each specific authoring action mentioned previously, did the authoring tool interface demonstrate provision of navigation to task-appropriate groups of controls according to Part 7.14.3 of ISO16071:2002(E)
(please be specific - if (so/not), how was it (so/not) demonstrated)?
What test procedure did you use?  What test environment did you use?</h2>  
<p>

-->
<hr>
<p>
AFTER THE INVESTIGATION:

<p>
Please answer the following questions for TIMES 1&2 (different) (Please enter them at this point:____),
 for every type of markup and example of content that had acceptable formats, that
you found in answers to previous questions:
 
<ul>

<li>Was a repair provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC1.1 
?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Was a repair provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC1.2?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Was a repair provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC1.3?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Was a repair provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC1.4?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Was a repair provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC2.1?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Was a repair provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC2.2?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Was a repair provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC2.3?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Was a repair provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC2.4?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Was a repair provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC2.5?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Was a repair provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC3.1?
If yes, why?  If no, why not?
<br>
<br>
<br>
<li>Was a repair provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC3.2?
If yes, why?  If no, why not?   
<br>
<br>
<br>   
<li>Was a repair provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC4.1?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Was a repair provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC4.2?
If yes, why?  If no, why not?   
<br>
<br>
<br>




</ul>


<hr>
<p>
Please answer the following questions for TIMES 1&2 (different)(Please enter them at this point:____),
 for example of updated/added web content x and/or instruction y as specified previously, that
you found in answers to previous questions:
(NOTE: x goes from 1 to n, where n is greater than or equal to 1)
(NOTE: y goes from 1 to m, where m is greater than or equal to 1)

<ul>

  

<li>Were manual repair(s) directly linked from check(s) provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC1.1 
?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Were manual repair(s) directly linked from check(s) provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC1.2?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Were manual repair(s) directly linked from check(s) provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC1.3?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Were manual repair(s) directly linked from check(s)  provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC1.4?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Were manual repair(s) directly linked from check(s) provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC2.1?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Were manual repair(s) directly linked from check(s) provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC2.2?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Were manual repair(s) directly linked from check(s) provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC2.3?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Were manual repair(s) directly linked from check(s) provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC2.4?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Were manual repair(s) directly linked from check(s) provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC2.5?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Were manual repair(s) directly linked from check(s) provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC3.1?
If yes, why?  If no, why not?
<br>
<br>
<br>
<li>Were manual repair(s) directly linked from check(s) provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC3.2?
If yes, why?  If no, why not?   
<br>
<br>
<br>   
<li>Were manual repair(s) directly linked from check(s) provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC4.1?
If yes, why?  If no, why not?   
<br>
<br>
<br>
<li>Were manual repair(s) directly linked from check(s) provided to you to make sure that web content x 
passed all of the (specific version of) WCAG20 Level 1, 2 and 3 Tests in the WCAG2.0 Test Suite for WCAG2.0 SC4.2?
If yes, why?  If no, why not?   
<br>
<br>
<br>




</ul>







<!--

<ul>
<li>Once a problem has been detected by the author or, preferably by the tool (see Checkpoint 3.2), the tool may assist the author to correct the problem?
<li> As with accessibility checking, the extent to which accessibility correction can be automated depends on the nature of the particular problems?
<li> Some repairs are easily automated, whereas others that require human judgment may be semi-automated at best?
<li>The checkpoints in guideline 4 require that implementations of correcting be:
   <ul>
    <li> clearly available to the author? (checkpoint 4.3) [Priority 2]
    <li> configurable? (checkpoint 4.X) [Priority 2]
    <li> integrated into the workflow of Web Content development? (checkpoint 4.1) [Priority 2]
    <li> naturally integrated into the appearance and interactive style of the tool? (checkpoint 4.4) [Priority 3]
</ul>
<li>Automate as much repairing as possible. Where necessary provide semi-automated repairing? Where neither of these options is reliable, provide manual repairing.
    <ul>
        <li> Automated: In automated tools, the tool is able to make repairs automatically, with no author input required. For example, a tool may be capable of automatically adding a document type to the header of a file that lacks this information. In these cases, very little, if any, author notification is required. This type of repair is usually appropriate for corrections of a syntactic or repetitive nature.

            Example 3.3.1(a): This illustration shows a sample of an announcement that an automated repair has been completed. An "undo " button is provided in case the author wishes to reverse the operation. In some cases, automated repairs might be completed with no author notification at all. (Source: mockup by AUWG)
            [longdesc missing]

        <li> Semi-Automated: In semi-automated repairing, the tool can provide some automated assistance to the author in performing corrections, but the author's input is still required before the repair can be complete. For example, the tool may prompt the author for a plain text string, but then be capable of handling all the markup required to add the text string to the content. In other cases, the tool may be able to narrow the choice of repair options, but still rely on the author to make the final selection. This type of repair is usually appropriate for corrections of a semantic nature.

            Example 3.3.1(b): This illustration shows a sample of a semi-automated repair in a WYSIWYG editor. The author has right-clicked on an image highlighted by the automated checker system. The author must then decide whether the label text that the tool suggests is appropriate. Whichever option the author chooses, the tool will handle the details of updating the content. (Source: mockup by AUWG)
            [longdesc missing]

        <li> Manual: In manual repairing, the tool provides the author with instructions for making the necessary correction, but does not automate the task in any substantial way. For example, the tool may move the cursor to start of the problem, but since this is not a substantial automation, the repair would still be considered "manual". Manual correction tools leave it up to the author to follow the instructions and make the repair by themselves. This is the most time consuming option for authors and allows the most opportunity for human error.

            Example 3.3.1(c): This illustration shows a sample manual repair. The problems have already been detected in the checking step and the selected offending elements in a code view have been highlighted. However, when it comes to repairing the problem, the only assistance that the tool provides is a context sensitive hint. The author is left to make sense of the hint and perform the repair without any automated assistance. (Source: mockup by AUWG)
            [longdesc missing]
    </ul>

<li> Implement a special-purpose correcting interface where appropriate. When problems require some human judgment, the simplest solution is often to display the property editing mechanism for the offending element?
<li> This has the advantage that the author is already somewhat familiar with the interface? However, this practice suffers from the drawback that it does not necessarily focus the author's attention on the dialog control(s) that are relevant to the required correction? 
<li> Another option is to display a special-purpose correction utility that includes only the input field(s) for the information currently required? A further advantage of this approach is that additional information and tips that the author may require in order to properly provide the requested information can be easily added?
<li> Notice that in the figure, a drop-down edit box has been used for the short text label field?
<li> This technique might be used to allow the author to select from text strings used previously for the alt-text of this image (see ATAG Checkpoint 3.5 for more)?

        Example 3.3.2: This illustration shows a sample of a special-purpose correction interface. The tool supports the author's repair task by providing a description of the problem, a preview (in this case of the image missing a label), tips for performing the repair, possible repair options (archived from previous repairs), and other information (in this case the name of the image file). (Source: mockup by AUWG)
        [longdesc missing]

<li> Checks can be automatically sequenced? In cases where there are likely to be many accessibility problems, it may be useful to implement a checking utility that presents accessibility problems and repair options in a sequential manner? This may take a form similar to a configuration wizard or a spell checker (see Figure 3.3.5)? In the case of a wizard, a complex interaction is broken down into a series of simple sequential steps that the author can complete one at a time? The later steps can then be updated "on-the-fly" to take into account the information provided by the author in earlier steps? A checker is a special case of a wizard in which the number of detected errors determines the number of steps? For example, word processors have checkers that display all the spelling problems one at a time in a standard template with places for the misspelled word, a list of suggested words, and "change to" word? The author also has correcting options, some of which can store responses to affect how the same situation can be handled later. In an accessibility problem checker, sequential prompting is an efficient way of correcting problems. However, because of the wide range of problems the checker needs to handle (i.e. missing text, missing structural information, improper use of color, etc.), the interface template will need to be even more flexible than that of a spell checker. Nevertheless, the template is still likely to include areas for identifying the problem (WYSIWYG or code-based according to the tool), suggesting multiple solutions, and choosing between or creating new solutions. In addition, the dialog may include context-sensitive instructive text to help the author with the current correction.

    NOTE-@@TB: Author should know what is the sequencing criteria@@

        Example 3.3.3: This illustration shows an example of a sequential accessibility checker, the special-purpose correction interface from Example 3.3.2 is supplemented with navigational controls for moving backwards and forwards through the list of repair tasks. (Source: mockup by AUWG)
        [longdesc missing]

<li>Where a tool is able to detect site-wide errors, allow the author to make site-wide corrections? This should not be used for equivalent alternatives when the function is not known with certainty (see ATAG Checkpoint 3.4)?

<li>Provide a mechanism for authors to navigate sequentially among uncorrected accessibility errors? This allows the author to quickly scan accessibility problems in context?

<li>Consult the Techniques For Accessibility Evaluation and Repair Tools [WAI-ER @@change to AERT@@] Public Working Draft document for evaluation and repair algorithms related to WCAG 1.0.@@rewording@@?

<li>For accessibility problems for which an authoring tool provides only manual repairs, the repair instructions must be directly linked from the corresponding check?

<li>Tool designer lists on form all web content types produced by the tool
<li>Tool designer lists on form all WCAG-capable formats supported for each content type mentioned previously
<li>Tool designer specifies on form whether any format selections of the tool are automatic 
<li>Author verifies on form that all of the following are true for each supported/selected format mentioned before (or N/A if not applicable?):  

<li>For every referenced format, all the WCAG tests are satisfied


</ul>
--><p>
<hr>
<ul>
<li>What test procedure did you use for SC3.3?  What test environment did you use for SC3.3?
<br>
<br>
<br>
<li>
SUMMARY QUESTION:Objectively, from your perspective, did this authoring tool "pass" 
("yes" or "N/A" answers to all non-OPTIONAL questions AFTER THE INVESTIGATION)  ATAG2.0 Success Criterion 3.3?
If yes, why?  If not, why not? (please be specific)
<br>
<br>
<br>
</ul> 
<p>

<hr>
<h2>Part 4 - Supplemental Questions</h2>

 
<h3>
Please give any other information you feel may be helpful (please be specific): 
</h3>
<p>
<br>
<br>
<br>
<h3>
Please comment on the quality of the questions asked and/or the specification/techniques (please be specific): 
</h3>
<p>
<br>
<br>
<br>
<h3>
What other questions do you feel might be helpful?  Do you have any bugs/issues with this form? (please be specific)  
</h3>
<p>
<br>
<br>
<br>
<h3>Date of completion of this form (template):</h3>
<p>
<br>
<br>
<br> 
<p>
Thank you very much!  Your evaluation will be logged and made publicly available.
</p>



   


</body>
</html>