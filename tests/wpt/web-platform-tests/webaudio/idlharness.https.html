<!DOCTYPE html>
<meta charset="utf-8">
<title>WebAudio IDL tests</title>
<link rel="help" href="https://webaudio.github.io/web-audio-api/"/>
<meta name="timeout" content="long"><!-- Heavy computation of the idl_objects -->
<script src="/resources/testharness.js"></script>
<script src="/resources/testharnessreport.js"></script>
<script src="/resources/WebIDLParser.js"></script>
<script src="/resources/idlharness.js"></script>
<script>
'use strict';

let sample_rate, context, buffer, worklet_node;

promise_test(async t => {
  const srcs = ['cssom', 'dom', 'html', 'uievents', 'mediacapture-main', 'webaudio'];
  const [cssom, dom, html, uievents, mediacapture, webaudio] =
      await Promise.all(
          srcs.map(i => fetch(`/interfaces/${i}.idl`).then(r => r.text())));

  const idl_array = new IdlArray();
  idl_array.add_idls(webaudio);

  // Dependencies of HTML
  idl_array.add_dependency_idls(html);
  idl_array.add_dependency_idls(uievents);
  idl_array.add_dependency_idls(dom);
  idl_array.add_dependency_idls(mediacapture);
  idl_array.add_dependency_idls(cssom);

  idl_array.add_untested_idls('interface SVGElement {};');
  idl_array.add_untested_idls('interface WorkletGlobalScope {};');
  idl_array.add_untested_idls('interface Worklet {};');

  try {
    sample_rate = 44100;
    context = new AudioContext;
    buffer = new AudioBuffer({length: 1, sampleRate: sample_rate});
    await context.audioWorklet.addModule(
      'the-audio-api/the-audioworklet-interface/processors/dummy-processor.js');
    worklet_node = new AudioWorkletNode(context, 'dummy');
  } catch (e) {
    // Ignore - errors will surface in each test_object below.
  }

  idl_array.add_objects({
    BaseAudioContext: [],
    AudioContext: ['context'],
    OfflineAudioContext: ['new OfflineAudioContext(1, 1, sample_rate)'],
    OfflineAudioCompletionEvent: [
      'new OfflineAudioCompletionEvent("", {renderedBuffer: buffer})'],
    AudioBuffer: ['buffer'],
    AudioNode: [],
    AudioParam: ['new AudioBufferSourceNode(context).playbackRate'],
    AudioScheduledSourceNode: [],
    AnalyserNode: ['new AnalyserNode(context)'],
    AudioBufferSourceNode: ['new AudioBufferSourceNode(context)'],
    AudioDestinationNode: ['context.destination'],
    AudioListener: ['context.listener'],
    AudioProcessingEvent: [`new AudioProcessingEvent('', {
      playbackTime: 0, inputBuffer: buffer, outputBuffer: buffer
    })`],
    BiquadFilterNode: ['new BiquadFilterNode(context)'],
    ChannelMergerNode: ['new ChannelMergerNode(context)'],
    ChannelSplitterNode: ['new ChannelSplitterNode(context)'],
    ConstantSourceNode: ['new ConstantSourceNode(context)'],
    ConvolverNode: ['new ConvolverNode(context)'],
    DelayNode: ['new DelayNode(context)'],
    DynamicsCompressorNode: ['new DynamicsCompressorNode(context)'],
    GainNode: ['new GainNode(context)'],
    IIRFilterNode: [
      'new IIRFilterNode(context, {feedforward: [1], feedback: [1]})'
    ],
    MediaElementAudioSourceNode: [
      'new MediaElementAudioSourceNode(context, {mediaElement: new Audio})'
    ],
    MediaStreamAudioDestinationNode: [
      'new MediaStreamAudioDestinationNode(context)'
    ],
    MediaStreamAudioSourceNode: [],
    MediaStreamTrackAudioSourceNode: [],
    OscillatorNode: ['new OscillatorNode(context)'],
    PannerNode: ['new PannerNode(context)'],
    PeriodicWave: ['new PeriodicWave(context)'],
    ScriptProcessorNode: ['context.createScriptProcessor()'],
    StereoPannerNode: ['new StereoPannerNode(context)'],
    WaveShaperNode: ['new WaveShaperNode(context)'],
    AudioWorklet: ['context.audioWorklet'],
    AudioWorkletGlobalScope: [],
    AudioParamMap: ['worklet_node.parameters'],
    AudioWorkletNode: ['worklet_node'],
    AudioWorkletProcessor: [],
  });
  idl_array.test();

}, 'Test driver');
</script>
